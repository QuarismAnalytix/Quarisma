/*
 * XSigma: High-Performance Quantitative Library
 *
 * SPDX-License-Identifier: GPL-3.0-or-later OR Commercial
 *
 * Comprehensive unit tests for smp_tools_api (Internal API)
 *
 * Tests cover:
 * - Singleton pattern
 * - Backend identification and verification
 * - Thread initialization and configuration
 * - Nested parallelism management
 * - Parallel scope detection
 * - Local scope configuration
 * - parallel_for integration with backend
 * - Backend-specific behavior
 * - Thread safety
 * - Edge cases and error handling
 */

#include <atomic>
#include <functional>
#include <vector>

#include "Testing/xsigmaTest.h"
#include "smp/common/smp_tools_api.h"
#include "smp/smp.h"

namespace xsigma
{
namespace detail
{
namespace smp
{

// ============================================================================
// Test Helper Classes
// ============================================================================

/**
 * @brief Simple functor for testing parallel_for
 */
class test_functor_internal
{
public:
    std::vector<std::atomic<int>>& data_;

    test_functor_internal(std::vector<std::atomic<int>>& data) : data_(data) {}

    void Execute(size_t begin, size_t end)
    {
        for (size_t i = begin; i < end; ++i)
        {
            data_[i].store(static_cast<int>(i * 3), std::memory_order_relaxed);
        }
    }
};

/**
 * @brief Functor that tracks parallel scope
 */
class scope_tracking_functor
{
public:
    std::atomic<bool>& was_in_parallel_scope_;

    scope_tracking_functor(std::atomic<bool>& flag) : was_in_parallel_scope_(flag) {}

    void Execute(size_t, size_t)
    {
        bool is_parallel = smp_tools_api::instance().is_parallel_scope();
        was_in_parallel_scope_.store(is_parallel, std::memory_order_relaxed);
    }
};

// ============================================================================
// Consolidated Test 1: Singleton and Backend Identification
// ============================================================================

XSIGMATEST(SmpToolsApi, singleton_and_backend_identification)
{
    {
        // Test 1: Singleton instance verification
        // Ensure singleton pattern returns same instance
        smp_tools_api& api1 = smp_tools_api::instance();
        smp_tools_api& api2 = smp_tools_api::instance();
        EXPECT_EQ(&api1, &api2);

        // Test 2: Backend type validation
        // Verify backend type is one of the valid types
        backend_type type = smp_tools_api::get_backend_type();
        EXPECT_TRUE(
            type == backend_type::std_thread || type == backend_type::TBB ||
            type == backend_type::OpenMP);

        // Test 3: Backend name validation
        // Verify backend name is non-null and valid
        const char* backend_name = smp_tools_api::get_backend();
        ASSERT_NE(backend_name, nullptr);
        std::string name_str(backend_name);
        EXPECT_TRUE(name_str == "std" || name_str == "tbb" || name_str == "openmp");

        // Test 4: Backend consistency check
        // Ensure backend type and name match
        if (type == backend_type::std_thread)
        {
            EXPECT_STREQ(backend_name, "std");
        }
        else if (type == backend_type::TBB)
        {
            EXPECT_STREQ(backend_name, "tbb");
        }
        else if (type == backend_type::OpenMP)
        {
            EXPECT_STREQ(backend_name, "openmp");
        }
    }

    // ============================================================================
    // Consolidated Test 2: Backend Setting Verification
    // ============================================================================

    {
        smp_tools_api& api             = smp_tools_api::instance();
        const char*    current_backend = smp_tools_api::get_backend();

        // Test 1: Setting to current backend should succeed
        bool result = api.set_backend(current_backend);
        EXPECT_TRUE(result);

        // Test 2: Setting to invalid backend should fail
        result = api.set_backend("InvalidBackend");
        EXPECT_FALSE(result);

        // Test 3: Setting null backend should fail
        result = api.set_backend(nullptr);
        EXPECT_FALSE(result);
    }

#if XSIGMA_HAS_OPENMP
    {
        smp_tools_api& api = smp_tools_api::instance();

        // Only OpenMP should succeed
        EXPECT_TRUE(api.set_backend("openmp"));
        EXPECT_FALSE(api.set_backend("tbb"));
        EXPECT_FALSE(api.set_backend("std"));
    }
#endif

#if XSIGMA_HAS_TBB
    {
        smp_tools_api& api = smp_tools_api::instance();

        // Only TBB should succeed
        EXPECT_TRUE(api.set_backend("tbb"));
        EXPECT_FALSE(api.set_backend("openmp"));
        EXPECT_FALSE(api.set_backend("std"));
    }
#endif

#if !XSIGMA_HAS_OPENMP && !XSIGMA_HAS_TBB
    {
        smp_tools_api& api = smp_tools_api::instance();

        // Only std_thread should succeed
        EXPECT_TRUE(api.set_backend("std"));
        EXPECT_FALSE(api.set_backend("openmp"));
        EXPECT_FALSE(api.set_backend("tbb"));
    }
#endif

    // ============================================================================
    // Consolidated Test 3: Thread Initialization and Configuration
    // ============================================================================

    {
        smp_tools_api& api = smp_tools_api::instance();

        // Test 1: Initialize with default (0 = auto)
        api.initialize(0);
        int num_threads = api.estimated_number_of_threads();
        EXPECT_GT(num_threads, 0);
        EXPECT_LE(num_threads, static_cast<int>(std::thread::hardware_concurrency() * 2));

        // Test 2: Initialize with specific thread count
        api.initialize(4);
        num_threads = api.estimated_number_of_threads();
        EXPECT_GT(num_threads, 0);

        // Test 3: Initialize with single thread
        api.initialize(1);
        num_threads = api.estimated_number_of_threads();
        EXPECT_GE(num_threads, 1);

        // Test 4: Initialize with negative threads (should handle gracefully)
        api.initialize(-5);
        num_threads = api.estimated_number_of_threads();
        EXPECT_GT(num_threads, 0);

        // Test 5: Estimated number of threads validation
        api.initialize(0);
        num_threads = api.estimated_number_of_threads();
        EXPECT_GT(num_threads, 0);
        EXPECT_LE(num_threads, 1024);  // Reasonable upper bound

        // Test 6: Estimated default number of threads
        int default_threads = api.estimated_default_number_of_threads();
        EXPECT_GT(default_threads, 0);
        EXPECT_LE(default_threads, static_cast<int>(std::thread::hardware_concurrency() * 2));

        // Test 7: Get internal desired number of threads
        api.initialize(8);
        int desired = api.get_internal_desired_number_of_thread();
        EXPECT_GE(desired, 0);
    }

    // ============================================================================
    // Consolidated Test 4: Nested Parallelism Management
    // ============================================================================

    {
        smp_tools_api& api = smp_tools_api::instance();

        // Test 1: Set nested parallelism to false
        api.set_nested_parallelism(false);
        bool is_nested = api.nested_parallelism();
        EXPECT_FALSE(is_nested);

        // Test 2: Set nested parallelism to true (may or may not be supported)
        api.set_nested_parallelism(true);
        SUCCEED();

        // Test 3: Toggle nested parallelism
        api.set_nested_parallelism(false);
        EXPECT_FALSE(api.nested_parallelism());
        api.set_nested_parallelism(true);
        // Backend-dependent behavior
        api.set_nested_parallelism(false);
        EXPECT_FALSE(api.nested_parallelism());
    }

    // ============================================================================
    // Consolidated Test 5: Parallel Scope Detection
    // ============================================================================

    {
        smp_tools_api& api = smp_tools_api::instance();

        // Test 1: Outside any parallel region
        bool is_parallel = api.is_parallel_scope();
        EXPECT_FALSE(is_parallel);

        // Test 2: Inside parallel_for (backend-dependent)
        std::atomic<bool>      was_parallel{false};
        scope_tracking_functor func(was_parallel);
        api.parallel_for(0, 100, 10, func);
        SUCCEED();

        // Test 3: Single thread detection
        bool is_single = api.single_thread();
        SUCCEED();

        // Test 4: Single thread with one thread initialized
        api.initialize(1);
        is_single = api.single_thread();
        SUCCEED();
    }

    // ============================================================================
    // Consolidated Test 6: Parallel For Execution
    // ============================================================================

    {
        smp_tools_api& api = smp_tools_api::instance();

        // Test 1: Basic parallel_for execution
        {
            const size_t                  size = 1000;
            std::vector<std::atomic<int>> data(size);
            for (auto& elem : data)
            {
                elem.store(-1, std::memory_order_relaxed);
            }

            test_functor_internal func(data);
            api.parallel_for(0, size, 100, func);

            // Verify all elements processed
            for (size_t i = 0; i < size; ++i)
            {
                EXPECT_EQ(data[i].load(std::memory_order_relaxed), static_cast<int>(i * 3))
                    << "Element " << i << " not processed correctly";
            }
        }

        // Test 2: Empty range
        {
            std::vector<std::atomic<int>> data(10);
            test_functor_internal         func(data);
            api.parallel_for(5, 5, 10, func);
            SUCCEED();
        }

        // Test 3: Single element
        {
            std::vector<std::atomic<int>> data(10);
            for (auto& elem : data)
            {
                elem.store(0, std::memory_order_relaxed);
            }
            test_functor_internal func(data);
            api.parallel_for(5, 6, 10, func);
            EXPECT_EQ(data[5].load(std::memory_order_relaxed), 15);  // 5 * 3
        }

        // Test 4: Large range
        {
            const size_t                  size = 100000;
            std::vector<std::atomic<int>> data(size);
            for (auto& elem : data)
            {
                elem.store(0, std::memory_order_relaxed);
            }

            test_functor_internal func(data);
            api.parallel_for(0, size, 1000, func);

            // Spot check
            EXPECT_EQ(data[0].load(std::memory_order_relaxed), 0);
            EXPECT_EQ(data[1000].load(std::memory_order_relaxed), 3000);
            EXPECT_EQ(
                data[size - 1].load(std::memory_order_relaxed), static_cast<int>((size - 1) * 3));
        }

        // Test 5: Various grain sizes
        {
            const size_t                  size = 1000;
            std::vector<std::atomic<int>> data(size);
            std::vector<size_t>           grains = {1, 10, 50, 100, 500, 1000, 5000};

            for (size_t grain : grains)
            {
                // Reset
                for (auto& elem : data)
                {
                    elem.store(0, std::memory_order_relaxed);
                }

                test_functor_internal func(data);
                api.parallel_for(0, size, grain, func);

                // Verify
                for (size_t i = 0; i < size; ++i)
                {
                    EXPECT_EQ(data[i].load(std::memory_order_relaxed), static_cast<int>(i * 3))
                        << "Failed with grain " << grain << " at index " << i;
                }
            }
        }

        // Test 6: Zero grain size (backend should handle)
        {
            std::vector<std::atomic<int>> data(100);
            for (auto& elem : data)
            {
                elem.store(0, std::memory_order_relaxed);
            }
            test_functor_internal func(data);
            api.parallel_for(0, 100, 0, func);
            SUCCEED();
        }
    }

    // ============================================================================
    // Consolidated Test 7: Thread Configuration Persistence
    // ============================================================================
    {
        smp_tools_api& api = smp_tools_api::instance();

        // Test 1: Refresh number of threads
        api.initialize(4);
        int desired = api.get_internal_desired_number_of_thread();
        EXPECT_GE(desired, 0);

        // Test 2: Thread configuration persistence
        api.initialize(8);
        int threads1 = api.estimated_number_of_threads();
        int threads2 = api.estimated_number_of_threads();
        EXPECT_EQ(threads1, threads2);
    }

    // Note: local_scope tests are better suited for the smp_tools level
    // and are comprehensively tested in TestSmpTools.cpp

    // ============================================================================
    // Consolidated Test 8: Thread Safety
    // ============================================================================

    {
        smp_tools_api& api = smp_tools_api::instance();

        // Test 1: Concurrent parallel_for calls
        {
            std::vector<std::atomic<int>> data1(1000);
            std::vector<std::atomic<int>> data2(1000);

            for (auto& elem : data1)
                elem.store(0, std::memory_order_relaxed);
            for (auto& elem : data2)
                elem.store(0, std::memory_order_relaxed);

            std::thread t1(
                [&api, &data1]()
                {
                    test_functor_internal func(data1);
                    api.parallel_for(0, 1000, 100, func);
                });

            std::thread t2(
                [&api, &data2]()
                {
                    test_functor_internal func(data2);
                    api.parallel_for(0, 1000, 100, func);
                });

            t1.join();
            t2.join();

            // Both should succeed
            for (size_t i = 0; i < 1000; ++i)
            {
                EXPECT_EQ(data1[i].load(std::memory_order_relaxed), static_cast<int>(i * 3));
                EXPECT_EQ(data2[i].load(std::memory_order_relaxed), static_cast<int>(i * 3));
            }
        }

        // Test 2: Concurrent initialization
        {
            std::thread t1([&api]() { api.initialize(2); });
            std::thread t2([&api]() { api.initialize(4); });
            std::thread t3([&api]() { api.initialize(8); });

            t1.join();
            t2.join();
            t3.join();

            // Should not crash
            int num_threads = api.estimated_number_of_threads();
            EXPECT_GT(num_threads, 0);
        }
    }

    // ============================================================================
    // Consolidated Test 9: Edge Cases
    // ============================================================================

    {
        smp_tools_api& api = smp_tools_api::instance();

        // Test 1: Multiple initializations
        {
            api.initialize(2);
            int threads1 = api.estimated_number_of_threads();

            api.initialize(4);
            int threads2 = api.estimated_number_of_threads();

            api.initialize(0);
            int threads3 = api.estimated_number_of_threads();

            // All should succeed
            EXPECT_GT(threads1, 0);
            EXPECT_GT(threads2, 0);
            EXPECT_GT(threads3, 0);
        }

        // Test 2: Excessive thread request
        {
            api.initialize(100000);
            int num_threads = api.estimated_number_of_threads();

            // Should be capped
            EXPECT_GT(num_threads, 0);
            EXPECT_LT(num_threads, 100000);
        }

        // Test 3: Reversed range in parallel_for
        {
            std::vector<std::atomic<int>> data(10);
            test_functor_internal         func(data);

            // Reversed range - should handle gracefully
            api.parallel_for(10, 0, 5, func);
            SUCCEED();
        }
    }

    // ============================================================================
    // Consolidated Test 10: Integration Tests
    // ============================================================================

    {
        smp_tools_api& api = smp_tools_api::instance();

        // Reset configuration
        api.initialize(4);
        api.set_nested_parallelism(false);

        // Verify state
        EXPECT_GT(api.estimated_number_of_threads(), 0);
        EXPECT_FALSE(api.is_parallel_scope());

        // Execute parallel work
        const size_t                  size = 10000;
        std::vector<std::atomic<int>> data(size);

        for (auto& elem : data)
        {
            elem.store(0, std::memory_order_relaxed);
        }

        test_functor_internal func(data);
        api.parallel_for(0, size, 1000, func);

        // Verify results
        for (size_t i = 0; i < size; ++i)
        {
            EXPECT_EQ(data[i].load(std::memory_order_relaxed), static_cast<int>(i * 3));
        }

        // Should not be in parallel scope after completion
        EXPECT_FALSE(api.is_parallel_scope());
    }

    {
        smp_tools_api& api = smp_tools_api::instance();

        // Verify backend
        backend_type type = smp_tools_api::get_backend_type();
        const char*  name = smp_tools_api::get_backend();

        ASSERT_NE(name, nullptr);

        // Verify setting current backend succeeds
        EXPECT_TRUE(api.set_backend(name));

        // Initialize and use
        api.initialize(0);

        std::vector<std::atomic<int>> data(100);
        for (auto& elem : data)
        {
            elem.store(0, std::memory_order_relaxed);
        }

        test_functor_internal func(data);
        api.parallel_for(0, 100, 10, func);

        // Verify execution
        for (size_t i = 0; i < 100; ++i)
        {
            EXPECT_EQ(data[i].load(std::memory_order_relaxed), static_cast<int>(i * 3));
        }
    }
}
}  // namespace smp
}  // namespace detail
}  // namespace xsigma
